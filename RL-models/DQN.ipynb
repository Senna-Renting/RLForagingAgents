{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959697fd-16aa-43ac-98e8-a9d798d17019",
   "metadata": {},
   "source": [
    "# DQN implementation in JAX\n",
    "\n",
    "I will implement the DQN algorithm as proposed by the following paper [1]. I will try to make the model as general as possible, so that it can be used for any type of problem. The model will be implemented in JAX, so that fast training and testing will be possible with the model.\n",
    "\n",
    "**References:**\n",
    "\n",
    "[1] M Roderick et al. 2017, Implementing the Deep Q-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "458892b3-9e00-4ecf-ba57-2ba5c9ed4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "from jax.nn import relu\n",
    "from jax import grad, value_and_grad, jit\n",
    "from jax.random import normal, uniform, PRNGKey, split\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65923641-3b93-49f0-b647-5c2f86643f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network hard-coded version for Inverted Pendulum case\n",
    "\n",
    "# class InvPendulumNN:\n",
    "#     def __init__(self, in_size=5, out_size=1, hidden_size=10, a_func=relu, seed=42):\n",
    "#         prng_key = PRNGKey(seed)\n",
    "#         self.W1 = normal(prng_key,shape=(hidden_size,in_size))\n",
    "#         self.W2 = normal(prng_key,shape=(out_size,hidden_size))\n",
    "#         self.params = {\"W1\": self.W1, \"W2\": self.W2}\n",
    "#         self.dW1 = jnp.zeros_like(self.W1)\n",
    "#         self.dW2 = jnp.zeros_like(self.W2)\n",
    "#         self.a_funcs = [a_func, a_func]\n",
    "#     def predict_loss(self, params, x):\n",
    "#         x_h = self.a_funcs[0](params[\"W1\"] @ x)\n",
    "#         return self.a_funcs[1](params[\"W2\"] @ x_h)\n",
    "#     def predict(self, x):\n",
    "#         x_h = self.a_funcs[0](self.params[\"W1\"] @ x)\n",
    "#         return self.a_funcs[1](self.params[\"W2\"] @ x_h)\n",
    "#     def loss(self, params, batch):\n",
    "#         x,y = batch\n",
    "#         return jnp.square(y - self.predict_loss(params, x)).mean()\n",
    "#     def parameters(self):\n",
    "#         return self.params\n",
    "#     def set_parameters(self, params):\n",
    "#         self.params = params\n",
    "\n",
    "prng_key = PRNGKey(42)\n",
    "\n",
    "class InvPendulumNNv2:\n",
    "    def predict(params, x):\n",
    "        x_h = relu(params[\"W1\"] @ x)\n",
    "        return relu(params[\"W2\"] @ x_h)\n",
    "    def loss(params, batch):\n",
    "        x,y = batch\n",
    "        return jnp.square(y - InvPendulumNNv2.predict(params, x)).mean()\n",
    "    def generate_params(in_size=5, hidden_size=10, out_size=1):\n",
    "        return {\n",
    "            \"W1\":normal(prng_key,shape=(hidden_size,in_size)),\n",
    "            \"W2\":normal(prng_key,shape=(out_size,hidden_size))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fef11409-2c3a-496f-a5b2-bfde05f0fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell block contains the general update mechanics for the parameters of a model\n",
    "def update(parameters, batch, opt_state, optimizer=optax.adam, loss_func=InvPendulumNNv2.loss):\n",
    "    params = parameters\n",
    "    loss, grads = value_and_grad(loss_func)(params, batch)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    return optax.apply_updates(params, updates), opt_state\n",
    "\n",
    "# Assumes the following data structure: data = (num_samples, batch_size)\n",
    "# Should only be given a single mini-batch of data to train on at the time\n",
    "partial(jit, static_argnums=(3))\n",
    "def train(X_train, y_train, params, lr, optimizer=optax.adam):\n",
    "    optimizer = optimizer(lr)\n",
    "    opt_state = optimizer.init(params)\n",
    "    for i in range(X_train.shape[1]):\n",
    "        params, opt_state = update(params, (X_train[:,i], y_train[:,i]), opt_state, optimizer=optimizer)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d637598f-b9b3-4b95-b27d-c28efba2ed98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n",
      "(1, 3)\n",
      "[[ 0.46015662  0.         30.585041  ]]\n",
      "[[ 0.7819718  0.        30.496143 ]]\n"
     ]
    }
   ],
   "source": [
    "# Example to test the train method\n",
    "X_train = jnp.array([[1.,-1.2,-1.], [2.,3.2,-2.], [3.,6.1,-3.], [4.,1.,-4.], [-5.,-3., -5.]])\n",
    "y_train = jnp.array([[10., 6., 3.]])\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "params = InvPendulumNNv2.generate_params(hidden_size=21)\n",
    "print(InvPendulumNNv2.predict(params, X_train))\n",
    "params = train(X_train, y_train, params, 1e-3)\n",
    "print(InvPendulumNNv2.predict(params, X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72910601-bdb8-4a7f-a7d3-9550c9c40ec4",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Okay so far I've figured out how to use the gradient method of jax as well as how to use the parameters and an optimizer to update the model iteratively over episodes. Next step will be to check it's performance one sample data from the OpenAI gym model. We will sample an episode of 500 steps in the environment, and use the retrieved data, to check if we can learn Q-values with this neural network. If we are able to do so, the next step will be to actually implement the DQN algorithm fully, with the neural network as a component of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7542ff90-ae0e-40d8-bf72-caad302cb51a",
   "metadata": {},
   "source": [
    "## Retrieve Inverted Pendulum Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23e10f9c-826a-4946-b345-101fbfe8c86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.01079811,  0.03859825, -0.67176235,  1.52850572]),\n",
       " 1.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make('InvertedPendulum-v4')\n",
    "env.reset()\n",
    "env.step(jnp.array([-2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f1ed7-7b31-4913-a7ea-c85ad52bca10",
   "metadata": {},
   "source": [
    "## The full DQN Algorithm for the Inverted Pendulum Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f02f6713-1c70-4d83-8937-c475f8d77f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, Q_params, key, eta=0.1, val_range=[-3,3], action_res=1000):\n",
    "    key, *subkeys = split(key, num=3) # Make a different key w.r.t the provided key (otherwise no random numbers are provided)\n",
    "    choice = uniform(subkeys[0], minval=0, maxval=1)\n",
    "    if choice <= eta:\n",
    "        return jnp.array([uniform(subkeys[1], minval=val_range[0], maxval=val_range[1])])\n",
    "    else: \n",
    "        state = jnp.expand_dims(state, axis=0) # Needed to ensure correct concatenation\n",
    "        states = jnp.repeat(state, action_res, axis=0)\n",
    "        actions = jnp.linspace(val_range[0], val_range[1], action_res)\n",
    "        actions = jnp.expand_dims(actions, axis=1) # Needed to ensure correct concatenation\n",
    "        nn_input = jnp.concatenate((states, actions), axis=1).transpose() # With transpose we ensure (num_samples, batch_size) shape required for the NN\n",
    "        print(nn_input.shape)\n",
    "        ys = InvPendulumNNv2.predict(Q_params, nn_input)\n",
    "        return actions[jnp.argmax(ys)] # Gets the best action out of our discretized space run through the network\n",
    "\n",
    "def add_to_stack(item, stack, stack_size=100):\n",
    "    if(len(stack) >= stack_size):\n",
    "        stack.pop(0)\n",
    "    stack.append(item)\n",
    "\n",
    "def DQN(env, num_episodes, lr=1e-3, memory_size=100):\n",
    "    prng_key = PRNGKey(42)\n",
    "    D = list()\n",
    "    Q_params = InvPendulumNNv2.generate_params()\n",
    "    Q_params_target = InvPendulumNNv2.generate_params() # Same rng key as Q_params, so weights are the same :)\n",
    "    for e in range(num_episodes):\n",
    "        e_done = False\n",
    "        state,info = env.reset()\n",
    "        while not e_done:\n",
    "            # Do episode stuf\n",
    "            action = get_action(state, Q_params, prng_key)\n",
    "            next_state, r, terminated, truncated = env.step(action)\n",
    "            add_to_stack(D, (state, action, r, next_state), stack_size=memory_size)\n",
    "            state = next_state\n",
    "            \n",
    "    return Q_params # Make sure to return the weights of our model\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a97bb092-af23-4d4a-b582-e3b341f49ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.335619]\n"
     ]
    }
   ],
   "source": [
    "# Test action function\n",
    "env.reset()\n",
    "state = env.step(jnp.array([-2]))[0] # Only need the state values of the step\n",
    "Q_params = InvPendulumNNv2.generate_params()\n",
    "prng_key = PRNGKey(42)\n",
    "print(get_action(state, Q_params, prng_key, eta=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51aacd4-34c6-4c80-8144-e0f3fab53b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ac8e2-0772-4471-a5c9-b7d12a571bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
