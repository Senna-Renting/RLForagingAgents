{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959697fd-16aa-43ac-98e8-a9d798d17019",
   "metadata": {},
   "source": [
    "# DQN implementation in JAX\n",
    "\n",
    "I will implement the DQN algorithm as proposed by the following paper [1]. I will try to make the model as general as possible, so that it can be used for any type of problem. The model will be implemented in JAX, so that fast training and testing will be possible with the model.\n",
    "\n",
    "**References:**\n",
    "\n",
    "[1] M Roderick et al. 2017, Implementing the Deep Q-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8dce90-b6b6-4982-8663-a622dcdbbb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym[classic_control]\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "     -------------------------------------- 721.7/721.7 kB 6.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\31614\\anaconda3\\lib\\site-packages (from gym[classic_control]) (2.0.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\31614\\anaconda3\\lib\\site-packages (from gym[classic_control]) (2.0.0)\n",
      "Collecting gym-notices>=0.0.4 (from gym[classic_control])\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\31614\\anaconda3\\lib\\site-packages (from gym[classic_control]) (6.8.0)\n",
      "Collecting pygame==2.1.0 (from gym[classic_control])\n",
      "  Downloading pygame-2.1.0-cp39-cp39-win_amd64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\31614\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gym[classic_control]) (3.6.0)\n",
      "Downloading pygame-2.1.0-cp39-cp39-win_amd64.whl (4.8 MB)\n",
      "   ---------------------------------------- 4.8/4.8 MB 13.3 MB/s eta 0:00:00\n",
      "Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827637 sha256=68032675f986f40243eb3fdb7f44e6fbc20af99714b36661d00107b322ae3b38\n",
      "  Stored in directory: c:\\users\\31614\\appdata\\local\\pip\\cache\\wheels\\af\\2b\\30\\5e78b8b9599f2a2286a582b8da80594f654bf0e18d825a4405\n",
      "Successfully built gym\n",
      "Installing collected packages: gym-notices, pygame, gym\n",
      "  Attempting uninstall: pygame\n",
      "    Found existing installation: pygame 2.5.2\n",
      "    Uninstalling pygame-2.5.2:\n",
      "      Successfully uninstalled pygame-2.5.2\n",
      "Successfully installed gym-0.26.2 gym-notices-0.0.8 pygame-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: gym 0.26.2 does not provide the extra 'classic-control'\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gym[classic_control] \n",
    "# Decided to go for different environments, as I don't have mujoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "458892b3-9e00-4ecf-ba57-2ba5c9ed4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "from jax.nn import leaky_relu\n",
    "from jax import grad, value_and_grad, jit, vmap\n",
    "from jax.random import normal, uniform, PRNGKey, split, choice\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "65923641-3b93-49f0-b647-5c2f86643f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network hard-coded version for Inverted Pendulum case\n",
    "\n",
    "# class InvPendulumNN:\n",
    "#     def __init__(self, in_size=5, out_size=1, hidden_size=10, a_func=relu, seed=42):\n",
    "#         prng_key = PRNGKey(seed)\n",
    "#         self.W1 = normal(prng_key,shape=(hidden_size,in_size))\n",
    "#         self.W2 = normal(prng_key,shape=(out_size,hidden_size))\n",
    "#         self.params = {\"W1\": self.W1, \"W2\": self.W2}\n",
    "#         self.dW1 = jnp.zeros_like(self.W1)\n",
    "#         self.dW2 = jnp.zeros_like(self.W2)\n",
    "#         self.a_funcs = [a_func, a_func]\n",
    "#     def predict_loss(self, params, x):\n",
    "#         x_h = self.a_funcs[0](params[\"W1\"] @ x)\n",
    "#         return self.a_funcs[1](params[\"W2\"] @ x_h)\n",
    "#     def predict(self, x):\n",
    "#         x_h = self.a_funcs[0](self.params[\"W1\"] @ x)\n",
    "#         return self.a_funcs[1](self.params[\"W2\"] @ x_h)\n",
    "#     def loss(self, params, batch):\n",
    "#         x,y = batch\n",
    "#         return jnp.square(y - self.predict_loss(params, x)).mean()\n",
    "#     def parameters(self):\n",
    "#         return self.params\n",
    "#     def set_parameters(self, params):\n",
    "#         self.params = params\n",
    "\n",
    "class InvPendulumNNv2:\n",
    "    def predict(params, x):\n",
    "        x_h = leaky_relu(params[\"W1\"] @ x)\n",
    "        return params[\"W2\"] @ x_h\n",
    "    def loss(params, batch):\n",
    "        x,y = batch\n",
    "        return jnp.square(y - InvPendulumNNv2.predict(params, x)).mean()\n",
    "    def generate_params(key, in_size=5, hidden_size=10, out_size=1):\n",
    "        return {\n",
    "            \"W1\":normal(key,shape=(hidden_size,in_size)),\n",
    "            \"W2\":normal(key,shape=(out_size,hidden_size))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fef11409-2c3a-496f-a5b2-bfde05f0fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell block contains the general update mechanics for the parameters of a model\n",
    "def update(parameters, batch, opt_state, optimizer=optax.adam, loss_func=InvPendulumNNv2.loss):\n",
    "    params = parameters\n",
    "    loss, grads = value_and_grad(loss_func)(params, batch)\n",
    "    grads = {key: jnp.clip(val, -1,1) for key, val in grads.items()} # Clip the gradients to a [-1,1] range (should improve stability of DQN algorithm)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    return optax.apply_updates(params, updates), opt_state\n",
    "\n",
    "# Assumes the following data structure: data = (num_samples, batch_size)\n",
    "# Should only be given a single mini-batch of data to train on at the time\n",
    "partial(jit, static_argnums=(3))\n",
    "def train(X_train, y_train, params, lr, optimizer=optax.adam):\n",
    "    optimizer = optimizer(lr)\n",
    "    opt_state = optimizer.init(params)\n",
    "    # Code below updates at each sample of the batch\n",
    "    # for i in range(X_train.shape[1]):\n",
    "    #    params, opt_state = update(params, (X_train[:,i], y_train[:,i]), opt_state, optimizer=optimizer)\n",
    "    # Code below updates once for the whole batch\n",
    "    params, opt_state = update(params, (X_train, y_train), opt_state, optimizer=optimizer)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d637598f-b9b3-4b95-b27d-c28efba2ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to test the train method\n",
    "X_train = jnp.array([[1.,-1.2,-1.], [2.,3.2,-2.], [3.,6.1,-3.], [4.,1.,-4.], [-5.,-3., -5.]])\n",
    "y_train = jnp.array([[10., 6., 3.]])\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "prng_key = PRNGKey(42)\n",
    "params = InvPendulumNNv2.generate_params(prng_key, hidden_size=21)\n",
    "# print(InvPendulumNNv2.predict(params, X_train))\n",
    "params = train(X_train, y_train, params, 1e-3)\n",
    "# print(InvPendulumNNv2.predict(params, X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72910601-bdb8-4a7f-a7d3-9550c9c40ec4",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Okay so far I've figured out how to use the gradient method of jax as well as how to use the parameters and an optimizer to update the model iteratively over episodes. Next step will be to check it's performance one sample data from the OpenAI gym model. We will sample an episode of 500 steps in the environment, and use the retrieved data, to check if we can learn Q-values with this neural network. If we are able to do so, the next step will be to actually implement the DQN algorithm fully, with the neural network as a component of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7542ff90-ae0e-40d8-bf72-caad302cb51a",
   "metadata": {},
   "source": [
    "## Retrieve Inverted Pendulum Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "23e10f9c-826a-4946-b345-101fbfe8c86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7385692  -0.67417765 -0.5784894 ]\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make('Pendulum-v1', render_mode=\"human\")\n",
    "env.reset()\n",
    "state, r, terminated, truncated, info = env.step(jnp.array([-2]))\n",
    "print(state)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f1ed7-7b31-4913-a7ea-c85ad52bca10",
   "metadata": {},
   "source": [
    "## The full DQN Algorithm for the Inverted Pendulum Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f02f6713-1c70-4d83-8937-c475f8d77f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, Q_params, key, eta=0.02, val_range=[-2,2], action_res=2000):\n",
    "    key, *subkeys = split(key, num=3) # Make a different key w.r.t the provided key (otherwise no random numbers are provided)\n",
    "    choice = uniform(subkeys[0], minval=0, maxval=1)\n",
    "    if choice <= eta:\n",
    "        return jnp.array([uniform(subkeys[1], minval=val_range[0], maxval=val_range[1])])\n",
    "    else: \n",
    "        return get_best_action(state, Q_params, val_range=val_range, action_res=action_res)\n",
    "\n",
    "def get_best_action(state, Q_params, val_range=[-2,2], action_res=2000):\n",
    "    state = jnp.expand_dims(state, axis=0) # Needed to ensure correct concatenation\n",
    "    states = jnp.repeat(state, action_res, axis=0)\n",
    "    actions = jnp.linspace(val_range[0], val_range[1], action_res)\n",
    "    actions = jnp.expand_dims(actions, axis=1) # Needed to ensure correct concatenation\n",
    "    nn_input = jnp.concatenate((states, actions), axis=1).transpose() # With transpose we ensure (num_samples, batch_size) shape required for the NN\n",
    "    ys = InvPendulumNNv2.predict(Q_params, nn_input)\n",
    "    return actions[jnp.argmax(ys)] # Gets the best action out of our discretized space run through the network\n",
    "    \n",
    "def initialize_memory(env, size, key, a_range=[-2,2]):\n",
    "    i = 0\n",
    "    state, info = env.reset()\n",
    "    state_mem = jnp.zeros(shape=(size, 3)) # Shape should be: size * dim(state)\n",
    "    next_state_mem = jnp.zeros(shape=(size, 3)) # Shape should be: size * dim(state)\n",
    "    action_mem = jnp.zeros(shape=(size, 1)) # Shape should be: size * dim(action)\n",
    "    r_mem = jnp.zeros(shape=(size, 1)) # Shape should be: size * dim(r)\n",
    "    terminated_mem = jnp.full((size, 1), False)\n",
    "    \n",
    "    while i < size:\n",
    "        key, subkey = split(key)\n",
    "        action = uniform(subkey, shape=(1,), minval=a_range[0],maxval=a_range[1])\n",
    "        next_state, r, terminated, truncated, info = env.step(action)\n",
    "        # Update arrays\n",
    "        state_mem, action_mem, r_mem, next_state_mem, terminated_mem = update_memory(i, (state_mem, state), \n",
    "                     (action_mem, action), \n",
    "                     (r_mem, r), \n",
    "                     (next_state_mem, next_state), \n",
    "                     (terminated_mem, terminated))\n",
    "        # Update state\n",
    "        state = next_state\n",
    "        if terminated or truncated:\n",
    "            state,info = env.reset()\n",
    "        i += 1\n",
    "    return state_mem, action_mem, r_mem, next_state_mem, terminated_mem \n",
    "        \n",
    "@jit\n",
    "def update_memory(i, state_tuple, action_tuple, r_tuple, next_state_tuple, terminated_tuple):\n",
    "    return state_tuple[0].at[i, :].set(state_tuple[1].flatten()), \\\n",
    "           action_tuple[0].at[i, :].set(action_tuple[1]), \\\n",
    "           r_tuple[0].at[i, :].set(r_tuple[1]), \\\n",
    "           next_state_tuple[0].at[i, :].set(next_state_tuple[1].flatten()), \\\n",
    "           terminated_tuple[0].at[i, :].set(terminated_tuple[1])\n",
    "    \n",
    "#@partial(jit, static_argnums=[6]) TODO: Make this method jit-able\n",
    "def get_minibatch(states, actions, rs, next_states, terminated, params, key, batch_size=6, gamma=0.8):\n",
    "    vget_action = vmap(get_best_action, (1, None), 1) # Vectorized version of the get_action method\n",
    "    key, subkey = split(key)\n",
    "    batch_indices = choice(subkey, jnp.arange(0,states.shape[0],1), shape=(batch_size,1))\n",
    "    xs = jnp.concatenate((jnp.take_along_axis(states, jnp.repeat(batch_indices, states.shape[1], axis=1), axis=0), \n",
    "                                  jnp.take_along_axis(actions, batch_indices, axis=0)), axis=1).transpose()\n",
    "    next_state_batch = jnp.take_along_axis(next_states, jnp.repeat(batch_indices, next_states.shape[1], axis=1), axis=0).transpose()\n",
    "    actions = vget_action(next_state_batch, params)\n",
    "    ys = jnp.where(jnp.take(terminated, batch_indices), \n",
    "                           jnp.take(rs, batch_indices),\n",
    "                           jnp.take(rs, batch_indices) + (gamma*InvPendulumNNv2.predict(params, \n",
    "                                                                                          jnp.concatenate((next_state_batch,\n",
    "                                                                                                           actions), axis=0)).transpose())\n",
    "                          ).transpose()\n",
    "    return xs, ys\n",
    "    \n",
    "\n",
    "# TODO: make the method below jit-able (this would include rewriting an existing openAI environment in jax for optimal performance)\n",
    "def DQN(num_episodes, lr=1e-3, eta=0.2, gamma=0.9, memory_size=200, batch_size=4, C=4, in_size=4, hidden_size=4):\n",
    "    prng_key = PRNGKey(42)\n",
    "    env = gym.make('Pendulum-v1', render_mode=\"None\")\n",
    "    state_mem, action_mem, r_mem, next_state_mem, terminated_mem = initialize_memory(env, memory_size, prng_key)\n",
    "    e_returns = jnp.zeros(shape=(num_episodes,))\n",
    "    prng_key, subkey = split(prng_key)\n",
    "    Q_params = InvPendulumNNv2.generate_params(subkey, in_size=in_size, hidden_size=hidden_size)\n",
    "    Q_params_target = InvPendulumNNv2.generate_params(subkey, in_size=in_size, hidden_size=hidden_size) # Same prng key as Q_params, so weights are the same :)\n",
    "    Q_params_best = Q_params_target\n",
    "    best_return = -9999\n",
    "    count = 0\n",
    "    mem_i = 0\n",
    "    for e in range(num_episodes):\n",
    "        e_done = False\n",
    "        e_return = 0\n",
    "        state,info = env.reset()\n",
    "        print(\"Current episode: \", e)\n",
    "        while not e_done:\n",
    "            # Sample an action\n",
    "            action = get_action(state, Q_params, prng_key, eta=eta)\n",
    "            next_state, r, terminated, truncated, info = env.step(action)\n",
    "            e_return += r\n",
    "            # Update memory arrays\n",
    "            state_mem, action_mem, r_mem, next_state_mem, terminated_mem = update_memory(mem_i, (state_mem, state), \n",
    "                                                                                         (action_mem, action), \n",
    "                                                                                         (r_mem, r), \n",
    "                                                                                         (next_state_mem, next_state), \n",
    "                                                                                         (terminated_mem, terminated))\n",
    "            # Update state for next loop\n",
    "            state = next_state\n",
    "            # Update network based on randomly sampled mini-batch\n",
    "            xs, ys = get_minibatch(state_mem, action_mem, r_mem, next_state_mem, terminated_mem, Q_params_target, prng_key, batch_size=batch_size, gamma=gamma)\n",
    "            Q_params = train(xs, ys, Q_params, lr)\n",
    "            # Update the stale network with the most recent found weights after every C steps\n",
    "            if count == C:\n",
    "                count = 0\n",
    "                Q_params_target = {key: jnp.copy(val) for key, val in Q_params.items()} \n",
    "            e_done = terminated or truncated # Ends the current episode when True\n",
    "            count += 1 # Counter for regulating network updating\n",
    "            mem_i = (mem_i + 1) % memory_size # Update the memory in sweeps with this index update\n",
    "        if e_return > best_return:\n",
    "            best_return = e_return\n",
    "            Q_params_best = Q_params_target\n",
    "        e_returns = e_returns.at[e].set(e_return) # Keep track off episode returns (rewards accumulated over the episode)\n",
    "            \n",
    "    return Q_params_best, e_returns # Make sure to return the weights of our model, and the returns obtained over the episodes\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f51aacd4-34c6-4c80-8144-e0f3fab53b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current episode:  0\n",
      "Current episode:  1\n",
      "Current episode:  2\n",
      "Current episode:  3\n",
      "Current episode:  4\n",
      "Current episode:  5\n",
      "Current episode:  6\n",
      "Current episode:  7\n",
      "Current episode:  8\n",
      "Current episode:  9\n"
     ]
    }
   ],
   "source": [
    "# Test DQN (it is working?)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Don't want all the warnings!\n",
    "\n",
    "model_params, returns = DQN(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "59eb81a9-36de-42fe-9158-7855186cd34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Returns across episodes')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot the returns obtained from the algorithm \n",
    "plt.figure()\n",
    "plt.plot(returns)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Return\")\n",
    "plt.title(\"Returns across episodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9347d2-940b-467f-a89f-522d71386a4c",
   "metadata": {},
   "source": [
    "## Make a function to render the learned model on the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "72cd3c38-bb16-46e3-be1e-7b8b07dff76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_DQN(env, params_learned):\n",
    "    prng_key = PRNGKey(42)\n",
    "    state,info = env.reset()\n",
    "    env.render()\n",
    "    done = False\n",
    "    while not done:\n",
    "        print(\"state:\", state)\n",
    "        action = get_action(state, params_learned, prng_key, eta=0)\n",
    "        state, r, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bdbc9a46-41ef-4e67-a6c4-81a8a3859d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [ 0.9182411  -0.39602187 -0.96014005]\n",
      "state: [ 0.8846571  -0.46624222 -1.5571564 ]\n",
      "state: [ 0.82793534 -0.56082356 -2.2068381 ]\n",
      "state: [ 0.73728544 -0.6755814  -2.927456  ]\n",
      "state: [ 0.5990677  -0.80069834 -3.7341418 ]\n",
      "state: [ 0.39916226 -0.9168803  -4.6346655 ]\n",
      "state: [ 0.12912515 -0.9916283  -5.622326  ]\n",
      "state: [-0.20240748 -0.9793014  -6.666047  ]\n",
      "state: [-0.5553983 -0.8315845 -7.700523 ]\n",
      "state: [-0.8353899  -0.54965776 -8.        ]\n",
      "state: [-0.9834919  -0.18095216 -8.        ]\n",
      "state: [-0.9763221   0.21632181 -8.        ]\n",
      "state: [-0.8150125   0.57944334 -8.        ]\n",
      "state: [-0.5307455   0.84753126 -7.8654175 ]\n",
      "state: [-0.18197194  0.9833037  -7.529769  ]\n",
      "state: [ 0.17078179  0.9853089  -7.0922914 ]\n",
      "state: [ 0.48318467  0.87551844 -6.65331   ]\n",
      "state: [ 0.7305466  0.6828628 -6.296671 ]\n",
      "state: [ 0.90155417  0.43266624 -6.0845237 ]\n",
      "state: [ 0.9895857   0.14394507 -6.060024  ]\n",
      "state: [ 0.985895   -0.16736504 -6.252065  ]\n",
      "state: [ 0.87660474 -0.48121116 -6.677589  ]\n",
      "state: [ 0.6456206  -0.76365834 -7.338497  ]\n",
      "state: [ 0.29727334 -0.95479244 -8.        ]\n",
      "state: [-0.09800681 -0.99518573 -8.        ]\n",
      "state: [-0.47781384 -0.8784611  -8.        ]\n",
      "state: [-0.78218454 -0.6230468  -8.        ]\n",
      "state: [-0.96306556 -0.26926708 -8.        ]\n",
      "state: [-0.99189967  0.12702397 -8.        ]\n",
      "state: [-0.8641346   0.50326073 -8.        ]\n",
      "state: [-0.6030352  0.7977146 -7.9225545]\n",
      "state: [-0.2629583  0.9648072 -7.6242685]\n",
      "state: [ 0.09380791  0.9955903  -7.200663  ]\n",
      "state: [ 0.4183651   0.90827894 -6.75397   ]\n",
      "state: [ 0.68184555  0.7314962  -6.3727612 ]\n",
      "state: [ 0.87063396  0.4919314  -6.124139  ]\n",
      "state: [ 0.9777072  0.2099729 -6.0551906]\n",
      "state: [ 0.9951687  -0.09817988 -6.197711  ]\n",
      "state: [ 0.9102514 -0.4140561 -6.571346 ]\n",
      "state: [ 0.70668113 -0.7075322  -7.1818876 ]\n",
      "state: [ 0.37537038 -0.9268749  -8.        ]\n",
      "state: [-0.01520306 -0.9998844  -8.        ]\n",
      "state: [-0.40337628 -0.9150342  -8.        ]\n",
      "state: [-0.7278653 -0.6857202 -8.       ]\n",
      "state: [-0.93744034 -0.34814602 -8.        ]\n",
      "state: [-0.99901414  0.04439273 -8.        ]\n",
      "state: [-0.90286565  0.42992285 -8.        ]\n",
      "state: [-0.6650129   0.74683183 -7.9775577 ]\n",
      "state: [-0.3350322  0.9422067 -7.717434 ]\n",
      "state: [ 0.02389726  0.99971443 -7.310779  ]\n",
      "state: [ 0.35876942  0.9334262  -6.8609934 ]\n",
      "state: [ 0.6365336   0.77124894 -6.4609237 ]\n",
      "state: [ 0.840995    0.54104286 -6.1824865 ]\n",
      "state: [ 0.96434444  0.2646504  -6.0767045 ]\n",
      "state: [ 0.9991568  -0.04105791 -6.178217  ]\n",
      "state: [ 0.93358016 -0.35836872 -6.5090103 ]\n",
      "state: [ 0.7515358  -0.65969235 -7.077787  ]\n",
      "state: [ 0.4410419 -0.8974865 -7.872556 ]\n",
      "state: [ 0.05672875 -0.9983896  -8.        ]\n",
      "state: [-0.33654058 -0.941669   -8.        ]\n",
      "state: [-0.6766776 -0.7362795 -8.       ]\n",
      "state: [-0.909982   -0.41464764 -8.        ]\n",
      "state: [-0.9996204  -0.02755206 -8.        ]\n",
      "state: [-0.9314406  0.3638934 -8.       ]\n",
      "state: [-0.71620685  0.6978881  -8.        ]\n",
      "state: [-0.3981715  0.917311  -7.776584 ]\n",
      "state: [-0.0400819  0.9991964 -7.388601 ]\n",
      "state: [ 0.302074   0.9532845 -6.9392033]\n",
      "state: [ 0.5916303  0.8062094 -6.52424  ]\n",
      "state: [ 0.8099452   0.58650553 -6.219583  ]\n",
      "state: [ 0.948366   0.3171781 -6.079704 ]\n",
      "state: [ 0.99987733  0.0156608  -6.1418204 ]\n",
      "state: [ 0.9535937 -0.3010965 -6.4300747]\n",
      "state: [ 0.79387736 -0.6080779  -6.955897  ]\n",
      "state: [ 0.5068799 -0.8620167 -7.7119555]\n",
      "state: [ 0.13118221 -0.9913583  -8.        ]\n",
      "state: [-0.26522627 -0.9641862  -8.        ]\n",
      "state: [-0.61976135 -0.78479034 -8.        ]\n",
      "state: [-0.87644976 -0.4814933  -8.        ]\n",
      "state: [-0.994766   -0.10217909 -8.        ]\n",
      "state: [-0.9560306   0.29326695 -8.        ]\n",
      "state: [-0.766359   0.6424126 -8.       ]\n",
      "state: [-0.4637689  0.8859562 -7.8181906]\n",
      "state: [-0.10933932  0.9940045  -7.4537234 ]\n",
      "state: [ 0.23853074  0.97113496 -7.00822   ]\n",
      "state: [ 0.53950244  0.84198403 -6.579869  ]\n",
      "state: [ 0.77218014  0.6354037  -6.2483807 ]\n",
      "state: [ 0.92682105  0.37550336 -6.071828  ]\n",
      "state: [ 0.9967673   0.08034309 -6.0902004 ]\n",
      "state: [ 0.97226524 -0.23388089 -6.329943  ]\n",
      "state: [ 0.8384655 -0.5449547 -6.8053536]\n",
      "state: [ 0.5800237  -0.81459963 -7.51407   ]\n",
      "state: [ 0.21701716 -0.9761678  -8.        ]\n",
      "state: [-0.18025161 -0.9836205  -8.        ]\n",
      "state: [-0.5490626 -0.8357812 -8.       ]\n",
      "state: [-0.8311887  -0.55599046 -8.        ]\n",
      "state: [-0.9820883  -0.18842098 -8.        ]\n",
      "state: [-0.9779379  0.208896  -8.       ]\n",
      "state: [-0.8193925  0.5732329 -8.       ]\n",
      "state: [-0.53697455  0.8435984  -7.870075  ]\n",
      "state: [-0.18883711  0.9820084  -7.5373764 ]\n",
      "state: [ 0.16431713  0.9864076  -7.10087   ]\n",
      "state: [ 0.47777387  0.8784829  -6.6610646 ]\n",
      "state: [ 0.7265098  0.6871561 -6.302202 ]\n",
      "state: [ 0.89903945  0.43786767 -6.0868354 ]\n",
      "state: [ 0.98872566  0.14973852 -6.0584345 ]\n",
      "state: [ 0.98690623 -0.16129504 -6.2461305 ]\n",
      "state: [ 0.87979865 -0.4753465  -6.667102  ]\n",
      "state: [ 0.6512708 -0.7588454 -7.3236117]\n",
      "state: [ 0.30435184 -0.9525597  -8.        ]\n",
      "state: [-0.09061761 -0.9958858  -8.        ]\n",
      "state: [-0.47128052 -0.88198334 -8.        ]\n",
      "state: [-0.7775386 -0.6288352 -8.       ]\n",
      "state: [-0.96104044 -0.27640778 -8.        ]\n",
      "state: [-0.99281514  0.11965836 -8.        ]\n",
      "state: [-0.86784613  0.49683306 -8.        ]\n",
      "state: [-0.6087482  0.7933635 -7.9273753]\n",
      "state: [-0.26949075  0.963003   -7.6323524 ]\n",
      "state: [ 0.08752869  0.996162   -7.2101    ]\n",
      "state: [ 0.4130402  0.9107128 -6.762979 ]\n",
      "state: [ 0.6778152  0.7352323 -6.3799443]\n",
      "state: [ 0.86802614  0.4965185  -6.12852   ]\n",
      "state: [ 0.97659576  0.21508296 -6.0561314 ]\n",
      "state: [ 0.99568194 -0.09283033 -6.194819  ]\n",
      "state: [ 0.9126046  -0.40884334 -6.5644417 ]\n",
      "state: [ 0.7110964  -0.70309454 -7.1710744 ]\n",
      "state: [ 0.3812394 -0.9244763 -7.998395 ]\n",
      "state: [-0.00886328 -0.9999607  -8.        ]\n",
      "state: [-0.39756668 -0.9175733  -8.        ]\n",
      "state: [-0.723503  -0.6903212 -8.       ]\n",
      "state: [-0.93521416 -0.35408258 -8.        ]\n",
      "state: [-0.99927557  0.03805788 -8.        ]\n",
      "state: [-0.9055733   0.42418984 -8.        ]\n",
      "state: [-0.669575   0.7427445 -7.981858 ]\n",
      "state: [-0.3404509  0.9402623 -7.724799 ]\n",
      "state: [ 0.01858264  0.9998273  -7.3196025 ]\n",
      "state: [ 0.3542111  0.9351655 -6.869732 ]\n",
      "state: [ 0.63305104  0.7741101  -6.468358  ]\n",
      "state: [ 0.83869195  0.5446061  -6.187775  ]\n",
      "state: [ 0.9632481   0.26861346 -6.079321  ]\n",
      "state: [ 0.9993178  -0.03693132 -6.1778607 ]\n",
      "state: [ 0.9351133 -0.3543489 -6.505559 ]\n",
      "state: [ 0.7545792 -0.656209  -7.071321 ]\n",
      "state: [ 0.44559494 -0.8952347  -7.8634777 ]\n",
      "state: [ 0.06179932 -0.9980886  -8.        ]\n",
      "state: [-0.33175308 -0.9433663  -8.        ]\n",
      "state: [-0.6729289 -0.7397071 -8.       ]\n",
      "state: [-0.9078641  -0.41926453 -8.        ]\n",
      "state: [-0.99946755 -0.03262926 -8.        ]\n",
      "state: [-0.933277    0.35915744 -8.        ]\n",
      "state: [-0.71974254  0.6942411  -8.        ]\n",
      "state: [-0.40270066  0.9153317  -7.7793193 ]\n",
      "state: [-0.04480939  0.99899554 -7.3928204 ]\n",
      "state: [ 0.29776853  0.9546381  -6.943574  ]\n",
      "state: [ 0.58812135  0.8087727  -6.527595  ]\n",
      "state: [ 0.80743116  0.58996177 -6.2210155 ]\n",
      "state: [ 0.94698316  0.32128325 -6.078544  ]\n",
      "state: [ 0.99979585  0.02020382 -6.137582  ]\n",
      "state: [ 0.9550653  -0.29639542 -6.422429  ]\n",
      "state: [ 0.7972005  -0.60371464 -6.9447255 ]\n",
      "state: [ 0.5122205 -0.858854  -7.6975117]\n",
      "state: [ 0.13733283 -0.99052495 -8.        ]\n",
      "state: [-0.2592367 -0.9658138 -8.       ]\n",
      "state: [-0.6148784 -0.7886219 -8.       ]\n",
      "state: [-0.8734444  -0.48692396 -8.        ]\n",
      "state: [-0.9941127  -0.10835141 -8.        ]\n",
      "state: [-0.9578324   0.28732744 -8.        ]\n",
      "state: [-0.7703315   0.63764364 -8.        ]\n",
      "state: [-0.46910095  0.88314456 -7.8217673 ]\n",
      "state: [-0.11504675  0.9933601  -7.4594088 ]\n",
      "state: [ 0.23324887  0.97241706 -7.014389  ]\n",
      "state: [ 0.5351381  0.8447646 -6.585076 ]\n",
      "state: [ 0.76898146  0.6392711  -6.2515025 ]\n",
      "state: [ 0.924929    0.38013992 -6.072049  ]\n",
      "state: [ 0.99633855  0.08549584 -6.086944  ]\n",
      "state: [ 0.973543   -0.22850403 -6.3228226 ]\n",
      "state: [ 0.8417656 -0.5398432 -6.7942004]\n",
      "state: [ 0.5855768  -0.81061697 -7.499083  ]\n",
      "state: [ 0.2236828 -0.974662  -8.       ]\n",
      "state: [-0.17352575 -0.9848293  -8.        ]\n",
      "state: [-0.5433384 -0.8395138 -8.       ]\n",
      "state: [-0.82736987 -0.5616574  -8.        ]\n",
      "state: [-0.98077786 -0.19512777 -8.        ]\n",
      "state: [-0.9793425   0.20220831 -8.        ]\n",
      "state: [-0.8232906   0.56762016 -8.        ]\n",
      "state: [-0.54255    0.8400235 -7.8742847]\n",
      "state: [-0.19499901  0.98080343 -7.544267  ]\n",
      "state: [ 0.15850547  0.9873581  -7.1086645 ]\n",
      "state: [ 0.47290435  0.88111377 -6.668146  ]\n",
      "state: [ 0.72287196  0.69098204 -6.3073106 ]\n",
      "state: [ 0.89676476  0.44250754 -6.089074  ]\n",
      "state: [ 0.98792905  0.15490697 -6.0571938 ]\n",
      "state: [ 0.98777616 -0.15587911 -6.2410135 ]\n",
      "state: [ 0.8826087  -0.47010833 -6.6579227 ]\n",
      "state: [ 0.6562647 -0.7545307 -7.310504 ]\n",
      "state: [ 0.31063175 -0.95053035 -8.        ]\n",
      "state: [-0.08404315 -0.9964621  -8.        ]\n",
      "state: [-0.46544948 -0.88507444 -8.        ]\n",
      "state: [-0.7733716 -0.633953  -8.       ]\n",
      "state: [-0.9591953 -0.2827443 -8.       ]\n"
     ]
    }
   ],
   "source": [
    "# Test rendering\n",
    "env = gym.make('Pendulum-v1', render_mode=\"human\")\n",
    "prng_key = PRNGKey(42)\n",
    "render_DQN(env, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ccff7-7072-48e9-9a65-0739dc36daf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
