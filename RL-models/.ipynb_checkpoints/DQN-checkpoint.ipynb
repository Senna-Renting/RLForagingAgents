{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959697fd-16aa-43ac-98e8-a9d798d17019",
   "metadata": {},
   "source": [
    "# DQN implementation in JAX\n",
    "\n",
    "I will implement the DQN algorithm as proposed by the following paper [1]. I will try to make the model as general as possible, so that it can be used for any type of problem. The model will be implemented in JAX, so that fast training and testing will be possible with the model.\n",
    "\n",
    "**References:**\n",
    "\n",
    "[1] M Roderick et al. 2017, Implementing the Deep Q-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8dce90-b6b6-4982-8663-a622dcdbbb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym[classic_control]\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "     -------------------------------------- 721.7/721.7 kB 6.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\31614\\anaconda3\\lib\\site-packages (from gym[classic_control]) (2.0.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\31614\\anaconda3\\lib\\site-packages (from gym[classic_control]) (2.0.0)\n",
      "Collecting gym-notices>=0.0.4 (from gym[classic_control])\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\31614\\anaconda3\\lib\\site-packages (from gym[classic_control]) (6.8.0)\n",
      "Collecting pygame==2.1.0 (from gym[classic_control])\n",
      "  Downloading pygame-2.1.0-cp39-cp39-win_amd64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\31614\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gym[classic_control]) (3.6.0)\n",
      "Downloading pygame-2.1.0-cp39-cp39-win_amd64.whl (4.8 MB)\n",
      "   ---------------------------------------- 4.8/4.8 MB 13.3 MB/s eta 0:00:00\n",
      "Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827637 sha256=68032675f986f40243eb3fdb7f44e6fbc20af99714b36661d00107b322ae3b38\n",
      "  Stored in directory: c:\\users\\31614\\appdata\\local\\pip\\cache\\wheels\\af\\2b\\30\\5e78b8b9599f2a2286a582b8da80594f654bf0e18d825a4405\n",
      "Successfully built gym\n",
      "Installing collected packages: gym-notices, pygame, gym\n",
      "  Attempting uninstall: pygame\n",
      "    Found existing installation: pygame 2.5.2\n",
      "    Uninstalling pygame-2.5.2:\n",
      "      Successfully uninstalled pygame-2.5.2\n",
      "Successfully installed gym-0.26.2 gym-notices-0.0.8 pygame-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: gym 0.26.2 does not provide the extra 'classic-control'\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gym[classic_control] \n",
    "# Decided to go for different environments, as I don't have mujoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "458892b3-9e00-4ecf-ba57-2ba5c9ed4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "from jax.nn import relu\n",
    "from jax import grad, value_and_grad, jit\n",
    "from jax.random import normal, uniform, PRNGKey, split, choice\n",
    "from functools import partial\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65923641-3b93-49f0-b647-5c2f86643f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network hard-coded version for Inverted Pendulum case\n",
    "\n",
    "# class InvPendulumNN:\n",
    "#     def __init__(self, in_size=5, out_size=1, hidden_size=10, a_func=relu, seed=42):\n",
    "#         prng_key = PRNGKey(seed)\n",
    "#         self.W1 = normal(prng_key,shape=(hidden_size,in_size))\n",
    "#         self.W2 = normal(prng_key,shape=(out_size,hidden_size))\n",
    "#         self.params = {\"W1\": self.W1, \"W2\": self.W2}\n",
    "#         self.dW1 = jnp.zeros_like(self.W1)\n",
    "#         self.dW2 = jnp.zeros_like(self.W2)\n",
    "#         self.a_funcs = [a_func, a_func]\n",
    "#     def predict_loss(self, params, x):\n",
    "#         x_h = self.a_funcs[0](params[\"W1\"] @ x)\n",
    "#         return self.a_funcs[1](params[\"W2\"] @ x_h)\n",
    "#     def predict(self, x):\n",
    "#         x_h = self.a_funcs[0](self.params[\"W1\"] @ x)\n",
    "#         return self.a_funcs[1](self.params[\"W2\"] @ x_h)\n",
    "#     def loss(self, params, batch):\n",
    "#         x,y = batch\n",
    "#         return jnp.square(y - self.predict_loss(params, x)).mean()\n",
    "#     def parameters(self):\n",
    "#         return self.params\n",
    "#     def set_parameters(self, params):\n",
    "#         self.params = params\n",
    "\n",
    "class InvPendulumNNv2:\n",
    "    def predict(params, x):\n",
    "        x_h = relu(params[\"W1\"] @ x)\n",
    "        return relu(params[\"W2\"] @ x_h)\n",
    "    def loss(params, batch):\n",
    "        x,y = batch\n",
    "        return jnp.square(y - InvPendulumNNv2.predict(params, x)).mean()\n",
    "    def generate_params(key, in_size=5, hidden_size=10, out_size=1):\n",
    "        return {\n",
    "            \"W1\":normal(key,shape=(hidden_size,in_size)),\n",
    "            \"W2\":normal(key,shape=(out_size,hidden_size))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef11409-2c3a-496f-a5b2-bfde05f0fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell block contains the general update mechanics for the parameters of a model\n",
    "def update(parameters, batch, opt_state, optimizer=optax.adam, loss_func=InvPendulumNNv2.loss):\n",
    "    params = parameters\n",
    "    loss, grads = value_and_grad(loss_func)(params, batch)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    return optax.apply_updates(params, updates), opt_state\n",
    "\n",
    "# Assumes the following data structure: data = (num_samples, batch_size)\n",
    "# Should only be given a single mini-batch of data to train on at the time\n",
    "partial(jit, static_argnums=(3))\n",
    "def train(X_train, y_train, params, lr, optimizer=optax.adam):\n",
    "    optimizer = optimizer(lr)\n",
    "    opt_state = optimizer.init(params)\n",
    "    for i in range(X_train.shape[1]):\n",
    "        params, opt_state = update(params, (X_train[:,i], y_train[:,i]), opt_state, optimizer=optimizer)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d637598f-b9b3-4b95-b27d-c28efba2ed98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n",
      "(1, 3)\n",
      "[[ 0.46015662  0.         30.585041  ]]\n",
      "[[ 0.7819718  0.        30.496143 ]]\n"
     ]
    }
   ],
   "source": [
    "# Example to test the train method\n",
    "X_train = jnp.array([[1.,-1.2,-1.], [2.,3.2,-2.], [3.,6.1,-3.], [4.,1.,-4.], [-5.,-3., -5.]])\n",
    "y_train = jnp.array([[10., 6., 3.]])\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "prng_key = PRNGKey(42)\n",
    "params = InvPendulumNNv2.generate_params(prng_key, hidden_size=21)\n",
    "print(InvPendulumNNv2.predict(params, X_train))\n",
    "params = train(X_train, y_train, params, 1e-3)\n",
    "print(InvPendulumNNv2.predict(params, X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72910601-bdb8-4a7f-a7d3-9550c9c40ec4",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Okay so far I've figured out how to use the gradient method of jax as well as how to use the parameters and an optimizer to update the model iteratively over episodes. Next step will be to check it's performance one sample data from the OpenAI gym model. We will sample an episode of 500 steps in the environment, and use the retrieved data, to check if we can learn Q-values with this neural network. If we are able to do so, the next step will be to actually implement the DQN algorithm fully, with the neural network as a component of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7542ff90-ae0e-40d8-bf72-caad302cb51a",
   "metadata": {},
   "source": [
    "## Retrieve Inverted Pendulum Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "23e10f9c-826a-4946-b345-101fbfe8c86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9966549  -0.08172476  0.18299925]\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make('Pendulum-v1', render_mode=\"human\")\n",
    "env.reset()\n",
    "state, r, terminated, truncated, info = env.step(jnp.array([-2]))\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f1ed7-7b31-4913-a7ea-c85ad52bca10",
   "metadata": {},
   "source": [
    "## The full DQN Algorithm for the Inverted Pendulum Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f02f6713-1c70-4d83-8937-c475f8d77f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, Q_params, key, eta=0.02, val_range=[-2,2], action_res=100):\n",
    "    key, *subkeys = split(key, num=3) # Make a different key w.r.t the provided key (otherwise no random numbers are provided)\n",
    "    choice = uniform(subkeys[0], minval=0, maxval=1)\n",
    "    if choice <= eta:\n",
    "        return jnp.array([uniform(subkeys[1], minval=val_range[0], maxval=val_range[1])])\n",
    "    else: \n",
    "        state = jnp.expand_dims(state, axis=0) # Needed to ensure correct concatenation\n",
    "        states = jnp.repeat(state, action_res, axis=0)\n",
    "        actions = jnp.linspace(val_range[0], val_range[1], action_res)\n",
    "        actions = jnp.expand_dims(actions, axis=1) # Needed to ensure correct concatenation\n",
    "        nn_input = jnp.concatenate((states, actions), axis=1).transpose() # With transpose we ensure (num_samples, batch_size) shape required for the NN\n",
    "        ys = InvPendulumNNv2.predict(Q_params, nn_input)\n",
    "        return actions[jnp.argmax(ys)] # Gets the best action out of our discretized space run through the network\n",
    "\n",
    "def add_to_stack(item, stack, stack_size=100):\n",
    "    if(len(stack) >= stack_size):\n",
    "        stack.pop(0)\n",
    "    stack.append(item)\n",
    "\n",
    "def get_minibatch(stack, amount, key):\n",
    "    indices = jnp.arange(0,len(stack),1)\n",
    "    choices = choice(key, indices, (amount,))\n",
    "    return itemgetter(*choices)(stack)\n",
    "\n",
    "def DQN(env, num_episodes, lr=2e-3, eta=0.02, memory_size=500, C=200, in_size=4, hidden_size=100):\n",
    "    prng_key = PRNGKey(42)\n",
    "    D = list()\n",
    "    prng_key, subkey = split(prng_key)\n",
    "    Q_params = InvPendulumNNv2.generate_params(subkey, in_size=in_size, hidden_size=hidden_size)\n",
    "    Q_params_target = InvPendulumNNv2.generate_params(subkey, in_size=in_size, hidden_size=hidden_size) # Same prng key as Q_params, so weights are the same :)\n",
    "    batch_size = 6\n",
    "    count = 0\n",
    "    for e in range(num_episodes):\n",
    "        e_done = False\n",
    "        state,info = env.reset()\n",
    "        print(\"Current episode: \", e)\n",
    "        while not e_done:\n",
    "            # Do episode stuf\n",
    "            action = get_action(state, Q_params, prng_key)\n",
    "            next_state, r, terminated, truncated, info = env.step(action)\n",
    "            add_to_stack((state, action, r, next_state, terminated), D, stack_size=memory_size)\n",
    "            state = next_state\n",
    "            prng_key, subkey = split(prng_key)\n",
    "            if len(D) >= batch_size:\n",
    "                batch = get_minibatch(D, batch_size, subkey)\n",
    "                xs = jnp.array([jnp.concatenate((state,action)) for state, action, r, next_state, terminated in batch]).transpose()\n",
    "                ys = jnp.array([[r if terminated else \n",
    "                                r + InvPendulumNNv2.predict(Q_params_target, jnp.concatenate((next_state,get_action(next_state, Q_params_target, prng_key)))).mean()\n",
    "                                for state, action, r, next_state, terminated in batch]]).transpose()\n",
    "                Q_params = train(xs, ys, Q_params, lr)\n",
    "            if count == C:\n",
    "                count = 0\n",
    "                Q_params_target = {key: jnp.copy(val) for key, val in Q_params.items()} \n",
    "            e_done = terminated or truncated # Ends the current episode when True\n",
    "            count += 1 # Counter for regulating network updating\n",
    "            \n",
    "    return Q_params_target # Make sure to return the weights of our model\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a97bb092-af23-4d4a-b582-e3b341f49ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.5570793]\n"
     ]
    }
   ],
   "source": [
    "# Test action function\n",
    "env = gym.make('Pendulum-v1', render_mode=\"None\")\n",
    "env.reset()\n",
    "state = env.step(jnp.array([-2]))[0] # Only need the state values of the step\n",
    "prng_key = PRNGKey(42)\n",
    "Q_params = InvPendulumNNv2.generate_params(prng_key)\n",
    "print(get_action(state, Q_params, prng_key, eta=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51aacd4-34c6-4c80-8144-e0f3fab53b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current episode:  0\n",
      "Current episode:  1\n",
      "Current episode:  2\n",
      "Current episode:  3\n",
      "Current episode:  4\n",
      "Current episode:  5\n",
      "Current episode:  6\n",
      "Current episode:  7\n",
      "Current episode:  8\n",
      "Current episode:  9\n",
      "Current episode:  10\n",
      "Current episode:  11\n",
      "Current episode:  12\n",
      "Current episode:  13\n",
      "Current episode:  14\n",
      "Current episode:  15\n",
      "Current episode:  16\n",
      "Current episode:  17\n"
     ]
    }
   ],
   "source": [
    "# Test DQN (it is working?)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Don't want all the warnings!\n",
    "\n",
    "env.reset()\n",
    "model_params = DQN(env,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9347d2-940b-467f-a89f-522d71386a4c",
   "metadata": {},
   "source": [
    "## Make a function to render the learned model on the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "72cd3c38-bb16-46e3-be1e-7b8b07dff76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_DQN(env, params_learned):\n",
    "    prng_key = PRNGKey(42)\n",
    "    state,info = env.reset()\n",
    "    env.render()\n",
    "    done = False\n",
    "    while not done:\n",
    "        print(\"state:\", state)\n",
    "        action = get_action(state, params_learned, prng_key, eta=0)\n",
    "        state, r, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bdbc9a46-41ef-4e67-a6c4-81a8a3859d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: [ 0.69030946  0.72351426 -0.15703644]\n",
      "state: [0.6872065  0.7264621  0.08559925]\n",
      "state: [0.67511046 0.7377167  0.33044586]\n",
      "state: [0.6532945 0.7571039 0.5837333]\n",
      "state: [0.6204761  0.78422534 0.8515613 ]\n",
      "state: [0.5748028  0.81829196 1.1397303 ]\n",
      "state: [0.51387066 0.85786766 1.4534492 ]\n",
      "state: [0.43482882 0.9005131  1.79685   ]\n",
      "state: [0.3346525 0.9423416 2.1722348]\n",
      "state: [0.21069601 0.97755164 2.5789912 ]\n",
      "state: [0.06164005 0.99809843 3.0121548 ]\n",
      "state: [-0.11112727  0.9938062   3.4607286 ]\n",
      "state: [-0.30187753  0.9533467   3.9060833 ]\n",
      "state: [-0.4992354  0.8664664  4.321093 ]\n",
      "state: [-0.6862081   0.72740525  4.6709433 ]\n",
      "state: [-0.84259737  0.53854406  4.916497  ]\n",
      "state: [-0.9499602   0.31237105  5.0204053 ]\n",
      "state: [-0.99755424  0.06989676  4.9546833 ]\n",
      "state: [-0.9863523  -0.16464837  4.707106  ]\n",
      "state: [-0.9288194 -0.3705327  4.28362  ]\n",
      "state: [-0.84465903 -0.5353047   3.7057202 ]\n",
      "state: [-0.7550404 -0.6556783  3.0042415]\n",
      "state: [-0.67803913 -0.73502576  2.212483  ]\n",
      "state: [-0.6264816  -0.77943623  1.3612136 ]\n",
      "state: [-0.6077301  -0.7941437   0.47663638]\n",
      "state: [-0.6242317  -0.7812393  -0.41897136]\n",
      "state: [-0.67383933 -0.7388779  -1.3049008 ]\n",
      "state: [-0.74952596 -0.66197497 -2.1590593 ]\n",
      "state: [-0.83882576 -0.5444     -2.9555404 ]\n",
      "state: [-0.9239627 -0.3824825 -3.6638405]\n",
      "state: [-0.9838533  -0.17897692 -4.2507024 ]\n",
      "state: [-0.9985261   0.05427359 -4.684935  ]\n",
      "state: [-0.95488864  0.2969641  -4.9442296 ]\n",
      "state: [-0.8511694  0.524891  -5.021507 ]\n",
      "state: [-0.6974388  0.7166444 -4.9278383]\n",
      "state: [-0.51181793  0.85909396 -4.6903553 ]\n",
      "state: [-0.3145645  0.9492361 -4.3460345]\n",
      "state: [-0.12298031  0.9924091  -3.9341075 ]\n",
      "state: [ 0.05117524  0.9986897  -3.4898007 ]\n",
      "state: [ 0.20184053  0.9794184  -3.0407834 ]\n",
      "state: [ 0.32739732  0.94488674 -2.6062198 ]\n",
      "state: [ 0.42903617  0.9032873  -2.1975546 ]\n",
      "state: [ 0.50935054  0.8605591  -1.8200891 ]\n",
      "state: [ 0.5713612   0.82069874 -1.4746698 ]\n",
      "state: [ 0.61794066  0.7862247  -1.1591457 ]\n",
      "state: [ 0.6515263  0.7586261 -0.8694772]\n",
      "state: [ 0.67400724  0.73872477 -0.6005076 ]\n",
      "state: [ 0.68670255  0.72693855 -0.34646407]\n",
      "state: [ 0.6903742   0.72345245 -0.10126017]\n",
      "state: [0.68524474 0.72831285 0.14132917]\n",
      "state: [0.67100364 0.74145406 0.3875638 ]\n",
      "state: [0.64679825 0.76266116 0.64365435]\n",
      "state: [0.6112162 0.7914637 0.9156502]\n",
      "state: [0.5622747  0.82695055 1.209248  ]\n",
      "state: [0.49745354 0.86749065 1.5294609 ]\n",
      "state: [0.4138297 0.9103543 1.8800789]\n",
      "state: [0.3084039 0.9512555 2.2628446]\n",
      "state: [0.17873478 0.98389727 2.6762862 ]\n",
      "state: [0.02398761 0.9997122  3.1142092 ]\n",
      "state: [-0.15359928  0.9881332   3.5639935 ]\n",
      "state: [-0.34708813  0.93783253  4.005093  ]\n",
      "state: [-0.54374063  0.8392533   4.408468  ]\n",
      "state: [-0.72551554  0.6882058   4.737908  ]\n",
      "state: [-0.8721042   0.48932016  4.954062  ]\n",
      "state: [-0.9663238   0.25732931  5.0210524 ]\n",
      "state: [-0.9998941   0.01455446  4.914049  ]\n",
      "state: [-0.97661376 -0.2150014   4.624965  ]\n",
      "state: [-0.91108865 -0.41221052  4.163714  ]\n",
      "state: [-0.82386094 -0.566792    3.5545561 ]\n",
      "state: [-0.7357114  -0.67729515  2.829462  ]\n",
      "state: [-0.66361576 -0.7480736   2.0214906 ]\n",
      "state: [-0.61911887 -0.7852973   1.1604354 ]\n",
      "state: [-0.6084032 -0.7936281  0.2714625]\n",
      "state: [-0.63285494 -0.77427036 -0.62375855]\n",
      "state: [-0.6892534 -0.7245204 -1.5044613]\n",
      "state: [-0.76936764 -0.6388063  -2.3478518 ]\n",
      "state: [-0.85945284 -0.51121503 -3.1269565 ]\n",
      "state: [-0.9407098 -0.3392124 -3.8103676]\n",
      "state: [-0.9918395  -0.12749274 -4.364777  ]\n",
      "state: [-0.9939364   0.10995636 -4.7603965 ]\n",
      "state: [-0.9362221   0.35140896 -4.977929  ]\n",
      "state: [-0.81976587  0.5726988  -5.0143723 ]\n",
      "state: [-0.6569451  0.7539384 -4.8848486]\n",
      "state: [-0.46690705  0.8843064  -4.619395  ]\n",
      "state: [-0.26960394  0.96297127 -4.256165  ]\n",
      "state: [-0.08119541  0.9966982  -3.8339365 ]\n",
      "state: [ 0.08792207  0.99612737 -3.3864126 ]\n",
      "state: [ 0.23284455  0.972514   -2.9393172 ]\n",
      "state: [ 0.35274044  0.9357212  -2.5099318 ]\n",
      "state: [ 0.44923174  0.8934153  -2.1081407 ]\n",
      "state: [ 0.5250801  0.8510528 -1.7380793]\n",
      "state: [ 0.58331066  0.8122491  -1.3997897 ]\n",
      "state: [ 0.62671375  0.77924955 -1.0906029 ]\n",
      "state: [ 0.6576064  0.7533617 -0.8061657]\n",
      "state: [ 0.6777471   0.7352951  -0.54114443]\n",
      "state: [ 0.6883254   0.72540206 -0.2896731 ]\n",
      "state: [ 0.6899783   0.72383004 -0.04562155]\n",
      "state: [0.682806   0.7305997  0.19725099]\n",
      "state: [0.66637504 0.74561673 0.44520077]\n",
      "state: [0.6397061 0.7686196 0.7044133]\n",
      "state: [0.6012559  0.79905653 0.980878  ]\n",
      "state: [0.5489131  0.83587945 1.2801704 ]\n",
      "state: [0.48004797 0.87724227 1.60708   ]\n",
      "state: [0.39168188 0.9201007  1.9650117 ]\n",
      "state: [0.2808738 0.9597447 2.3550873]\n",
      "state: [0.14544195 0.98936677 2.7748957 ]\n",
      "state: [-0.01488583  0.9998892   3.2169209 ]\n",
      "state: [-0.1969326  0.980417   3.6668377]\n",
      "state: [-0.39248863  0.9197568   4.1021504 ]\n",
      "state: [-0.5874743   0.80924284  4.491968  ]\n",
      "state: [-0.76295966  0.64644605  4.7989    ]\n",
      "state: [-0.89881825  0.4383215   4.9837346 ]\n",
      "state: [-0.9794447   0.20171303  5.012476  ]\n",
      "state: [-0.9991968  -0.04007073  4.8637605 ]\n",
      "state: [-0.9646282  -0.26361403  4.5337076 ]\n",
      "state: [-0.8922165  -0.45160794  4.035997  ]\n",
      "state: [-0.8030316 -0.5959364  3.3972912]\n",
      "state: [-0.7172503  -0.69681567  2.650339  ]\n",
      "state: [-0.6506665  -0.75936365  1.8277271 ]\n",
      "state: [-0.61355245 -0.78965396  0.9582044 ]\n",
      "state: [-0.6109447  -0.79167324  0.06596393]\n",
      "state: [-0.6431791  -0.7657158  -0.82779104]\n",
      "state: [-0.7059381  -0.70827353 -1.7020779 ]\n",
      "state: [-0.7897559  -0.61342126 -2.533283  ]\n",
      "state: [-0.87962747 -0.4756633  -3.2933488 ]\n",
      "state: [-0.955863   -0.29381266 -3.9500964 ]\n",
      "state: [-0.997212  -0.0746209 -4.4704556]\n",
      "state: [-0.9861492   0.16586071 -4.8264217 ]\n",
      "state: [-0.9144166   0.40477434 -5.002026  ]\n",
      "state: [-0.7858949  0.6183601 -4.998445 ]\n",
      "state: [-0.6150176  0.7885134 -4.8346753]\n",
      "state: [-0.42163143  0.9067673  -4.54329   ]\n",
      "state: [-0.22513638  0.97432727 -4.1632147 ]\n",
      "state: [-0.04044852  0.9991816  -3.7324693 ]\n",
      "state: [ 0.12337941  0.9923596  -3.283083  ]\n",
      "state: [ 0.2625223   0.96492594 -2.8388133 ]\n",
      "state: [ 0.37684813  0.9262751  -2.415119  ]\n",
      "state: [ 0.4683407   0.88354796 -2.0204127 ]\n",
      "state: [ 0.5398841   0.84173936 -1.6577516 ]\n",
      "state: [ 0.59448236  0.8041086  -1.3264471 ]\n",
      "state: [ 0.6348312   0.77265084 -1.0233656 ]\n",
      "state: [ 0.6631234   0.74851006 -0.7438775 ]\n",
      "state: [ 0.6809863   0.73229617 -0.48249492]\n",
      "state: [ 0.689481    0.7243037  -0.23327279]\n",
      "state: [0.6891204 0.7246468 0.009955 ]\n",
      "state: [0.6798826  0.73332095 0.25344014]\n",
      "state: [0.66121036 0.75020057 0.50343084]\n",
      "state: [0.63199663 0.7749711  0.7660813 ]\n",
      "state: [0.5905672 0.8069885 1.0473096]\n",
      "state: [0.5346841 0.845052  1.352551 ]\n",
      "state: [0.46161678 0.8870795  1.68634   ]\n",
      "state: [0.36835077 0.9296869  2.0516496 ]\n",
      "state: [0.25204095 0.9677166  2.4489148 ]\n",
      "state: [0.11082547 0.99383986 2.8747022 ]\n",
      "state: [-0.05492285  0.9984906   3.320082  ]\n",
      "state: [-0.24100186  0.97052467  3.76895   ]\n",
      "state: [-0.43788084  0.899033    4.1968436 ]\n",
      "state: [-0.6301886  0.7764421  4.5711184]\n",
      "state: [-0.7983008  0.6022589  4.85345  ]\n",
      "state: [-0.92258406  0.38579607  5.005144  ]\n",
      "state: [-0.9893105   0.14582416  4.994491  ]\n",
      "state: [-0.9955996  -0.09370928  4.803859  ]\n",
      "state: [-0.95063335 -0.31031638  4.433577  ]\n",
      "state: [-0.87246716 -0.48867273  3.90084   ]\n",
      "state: [-0.7824009 -0.6227751  3.2343354]\n",
      "state: [-0.69982255 -0.7143167   2.4672542 ]\n",
      "state: [-0.6392889 -0.7689666  1.6315166]\n",
      "state: [-0.6098201  -0.79253983  0.75479156]\n",
      "state: [-0.61533767 -0.7882636  -0.13961333]\n",
      "state: [-0.65513015 -0.75551605 -1.0308111 ]\n",
      "state: [-0.72375417 -0.69005793 -1.8974481 ]\n",
      "state: [-0.81048334 -0.58576167 -2.7149916 ]\n",
      "state: [-0.8990927 -0.4377583 -3.4543128]\n",
      "state: [-0.96916616 -0.24640808 -4.0826316 ]\n",
      "state: [-0.9997878  -0.02059896 -4.5674376 ]\n",
      "state: [-0.9751179   0.22168675 -4.882887  ]\n",
      "state: [-0.8895784   0.45678255 -5.0166216 ]\n",
      "state: [-0.7497734   0.66169465 -4.974035  ]\n",
      "state: [-0.5719092  0.8203169 -4.777764 ]\n",
      "state: [-0.3762125  0.9265334 -4.4625263]\n",
      "state: [-0.18131532  0.983425   -4.067626  ]\n",
      "state: [-8.2091516e-04  9.9999964e-01 -3.6300573e+00]\n",
      "state: [ 0.15752313  0.9875153  -3.1800575 ]\n",
      "state: [ 0.29088625  0.95675766 -2.7394211 ]\n",
      "state: [ 0.39975142  0.9166236  -2.321853  ]\n",
      "state: [ 0.48640013  0.8737362  -1.9343852 ]\n",
      "state: [ 0.5537983   0.83265084 -1.579083  ]\n",
      "state: [ 0.6049068  0.7962963 -1.2545949]\n",
      "state: [ 0.64231694  0.76643914 -0.95737267]\n",
      "state: [ 0.6680943   0.74407667 -0.68254334]\n",
      "state: [ 0.6837351   0.7297303  -0.42448583]\n",
      "state: [ 0.69017315  0.72364426 -0.1771881 ]\n",
      "state: [0.6877979  0.72590226 0.0655451 ]\n",
      "state: [0.6764653  0.7364745  0.30997178]\n",
      "state: [0.6554936 0.7552007 0.5623277]\n",
      "state: [0.62364715 0.781706   0.8287282 ]\n",
      "state: [0.57912034 0.81524205 1.1150078 ]\n",
      "state: [0.51955265 0.8544384  1.4264393 ]\n",
      "state: [0.44212276 0.89695454 1.7672681 ]\n",
      "state: [0.34380388 0.9390415  2.139984  ]\n"
     ]
    }
   ],
   "source": [
    "# Test rendering\n",
    "env = gym.make('Pendulum-v1', render_mode=\"human\")\n",
    "prng_key = PRNGKey(42)\n",
    "render_DQN(env, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ccff7-7072-48e9-9a65-0739dc36daf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
